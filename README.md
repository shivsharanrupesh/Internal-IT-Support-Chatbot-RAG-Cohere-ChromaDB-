# Internal-IT-Support-Chatbot-RAG-Cohere-ChromaDB-

A next-gen, Retrieval-Augmented Generation (RAG) chatbot for instant, reliable IT supportâ€”using your company's official PDF knowledge base.

ğŸ“– Table of Contents
Overview

Architecture

Features

Project Structure

Setup

Usage

How It Works

Troubleshooting

Extending

Security

Credits

ğŸ“ Overview
This project provides a production-ready RAG chatbot that answers employeesâ€™ IT and tech support questions by searching your companyâ€™s PDF documentation.

No more waiting for a helpdesk agent!

All answers come from your companyâ€™s own docs (never hallucinated, always transparent).

ğŸ—ï¸ Architecture
PDF Ingestion:
Parses/splits PDFs from /data and creates semantic embeddings with Cohere.

Vector Store:
Stores and searches document chunks using ChromaDB.

RAG Pipeline:
Combines retrieval (via embeddings) and generative AI (Cohere LLM).

Chat Memory:
Multi-turn chat with session memory (via mem0).

APIs:
Backend (FastAPI) and web chat frontend (Streamlit).

âœ¨ Features
Instant answers for IT issues using company-approved docs only.

Source referencingâ€”shows which PDF and page the answer came from.

Multi-turn conversationâ€”remembers context per session.

Fully local, secure, and extendable.

No hardcoded secretsâ€”all keys via environment variables.

ğŸ“‚ Project Structure
graphql
Copy
Edit
rag-it-support-chatbot/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ ingest.py        # PDF loader, chunker, embedder, vectorstore builder
â”‚   â”œâ”€â”€ rag_chain.py     # RAG pipeline: Retriever + LLM + Memory
â”‚   â””â”€â”€ api.py           # FastAPI backend (/ask endpoint)
â”œâ”€â”€ chat_ui.py           # Streamlit chat UI
â”œâ”€â”€ requirements.txt     # All dependencies
â”œâ”€â”€ README.md
â”œâ”€â”€ data/                # Put your company PDFs here
â””â”€â”€ memory_store/        # Created at runtime for session memory
âš™ï¸ Setup
Requirements:

Python 3.9+

Cohere API Key

IT documentation as PDF in /data

1. Clone and Install
sh
Copy
Edit
git clone https://github.com/your-org/rag-it-support-chatbot.git
cd rag-it-support-chatbot
pip install -r requirements.txt
2. Configure Environment
sh
Copy
Edit
# Set your Cohere API Key
export COHERE_API_KEY=your-cohere-api-key      # Linux/macOS
set COHERE_API_KEY=your-cohere-api-key         # Windows

# Optional: Set persistent vector store directory
export CHROMA_DB_DIR=your/path/to/vectorstore
3. Add IT PDFs
Put your companyâ€™s FAQ, policy, and troubleshooting PDFs in data/.

4. Ingest Documents
sh
Copy
Edit
python app/ingest.py
5. Start Backend API
sh
Copy
Edit
uvicorn app.api:app --reload
6. Start Frontend (Chat UI)
sh
Copy
Edit
streamlit run chat_ui.py
ğŸš€ Usage
Open http://localhost:8501 in your browser.

Type your IT support question.

See answers pulled from company documentationâ€”with sources and context!

Multi-turn (conversational) support: the bot remembers previous chat for your session.

ğŸ§  How It Works
Question asked:
Employee asks a question via Streamlit UI.

Chunk retrieval:
System finds relevant PDF chunks via ChromaDB and Cohere embeddings.

RAG chain:
Cohere LLM receives both the question and retrieved document context to generate a reliable answer.

References:
The bot always cites which PDF(s) and page(s) were used for each answer.

Session memory:
Each chat is tracked via unique session ID, preserving context and history.

ğŸ› ï¸ Troubleshooting
No PDFs found:
Ensure at least one .pdf file exists in /data.

Cohere API errors:
Make sure COHERE_API_KEY is set in your environment.

Vectorstore not persistent:
Set CHROMA_DB_DIR to a directory for disk persistence.

Streamlit cannot connect:
Confirm FastAPI backend is running at localhost:8000.

ğŸ§© Extending
Add authentication (SSO/LDAP) for personalized experience.

Integrate escalation to human IT agents.

Add analytics for support trends.

Support more document formats (Word, HTML).

Containerize for easy deployment (add Docker support).

ğŸ” Security
No API keys are ever committedâ€”always use environment variables.

All answers and context are strictly sourced from your private company docs.

ğŸ™ Credits
LangChain

ChromaDB

Cohere

Streamlit

mem0
